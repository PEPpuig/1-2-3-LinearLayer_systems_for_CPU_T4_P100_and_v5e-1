import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.profiler import profile, ProfilerActivity
import torch.cuda as cuda
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_digits
from torch.utils.data import TensorDataset, DataLoader

# Verificar GPU
if torch.cuda.is_available():
    print(f"GPU: {cuda.get_device_name(0)}")
    device = "cuda"
else:
    print("No GPU available, using CPU")
    device = "cpu"

# Datos: flatten 64 features ‚Üí 10 clases
print("Cargando dataset digits...")
digits = load_digits()
X, Y = digits.data, digits.target
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=11)

train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32),
                              torch.tensor(Y_train))
test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32),
                             torch.tensor(Y_test))

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)

# ‚úÖ SOLO nn.Linear(64 ‚Üí 10) UNA CAPA
model = nn.Linear(64, 10).to(device)

optimizer = optim.SGD(model.parameters(), lr=0.001)
loss_fn = nn.CrossEntropyLoss()

# Warmup batch
print("Preparando warmup batch...")
it = iter(train_loader)
batch = next(it)
x = batch[0].to(device)      # [64, 64]
targets = batch[1].to(device) # [64]

print(f"Input: {x.shape} ‚Üí Linear(64,10) ‚Üí Output: [64,10]")
print("üöÄ Profiling nn.Linear...")

activities = [ProfilerActivity.CPU, ProfilerActivity.CUDA]
with profile(activities=activities, 
             with_stack=True, 
             record_shapes=True, 
             with_modules=True) as prof:
    
    optimizer.zero_grad()
    outputs = model(x)           
    loss = loss_fn(outputs, targets)
    loss.backward()
    optimizer.step()
    
    if device == "cuda":
        torch.cuda.synchronize()     

# Export trace - GUARDA DIRECTAMENTE EN EL DIRECTORIO ACTUAL
trace_path = "trace_linear_windows.json"
prof.export_chrome_trace(trace_path)
print(f"\n‚úÖ TRACE GUARDADO: {os.path.abspath(trace_path)}")
print(f"üìÅ Tama√±o archivo: {os.path.getsize(trace_path) / 1024:.1f} KB")

print("\nüéØ INSTRUCCIONES:")
print("1. Abre Chrome://tracing/")
print("2. Load ‚Üí Selecciona el archivo trace_linear_windows.json")
print("3. üîç Busca: aten::addmm (GEMM CUDA) | Stream 7 | cudaMemcpyHtoD")
print("\n‚ö° addmm CUDA kernel ~100-300¬µs | PCIe bound peque√±o batch | Perfecto baseline")
